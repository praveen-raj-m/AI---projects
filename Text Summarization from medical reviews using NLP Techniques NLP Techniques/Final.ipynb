{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "eEdPfVA0zw6T"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c5675f9dbdc44c859301b7d2f9cf4a33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7c6e12a9490f44aea776964859a3bf97",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_66bfbdf75b0d420684ac8a6316120dcb",
              "IPY_MODEL_a98fbdced06b40adbebef133a1cd5355"
            ]
          }
        },
        "7c6e12a9490f44aea776964859a3bf97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "66bfbdf75b0d420684ac8a6316120dcb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_896babc0cc0f49afa3b68d4e9fd973fe",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 244733649,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 244733649,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9629b88a03c442c386f7bce7f0a8d0c3"
          }
        },
        "a98fbdced06b40adbebef133a1cd5355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e28648d5371140349479179792d2c216",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 245M/245M [00:19&lt;00:00, 12.6MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_709235cec4294388b411e8872a14f17d"
          }
        },
        "896babc0cc0f49afa3b68d4e9fd973fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9629b88a03c442c386f7bce7f0a8d0c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e28648d5371140349479179792d2c216": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "709235cec4294388b411e8872a14f17d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nikewinchester/NLPTextSummarization/blob/main/Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKRX-bAlyuF_"
      },
      "source": [
        "## **Installing and Importing necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIITAstJ2jmu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28d1c85a-166b-4c05-b40d-743f9fc26a22"
      },
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install rake-nltk"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: sentence-transformers in /usr/local/lib/python3.7/dist-packages (1.1.1)\n",
            "Requirement already satisfied, skipping upgrade: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.8.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.19.5)\n",
            "Requirement already satisfied, skipping upgrade: transformers<5.0.0,>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.6.1)\n",
            "Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.9.1+cu101)\n",
            "Requirement already satisfied, skipping upgrade: sentencepiece in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.1.95)\n",
            "Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sentence-transformers) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers) (3.7.4.3)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from nltk->sentence-transformers) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.45)\n",
            "Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (4.0.1)\n",
            "Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.10.2)\n",
            "Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2019.12.20)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (20.9)\n",
            "Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=3.1.0->sentence-transformers) (0.0.8)\n",
            "Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers) (7.1.2)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sentence-transformers) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=3.1.0->sentence-transformers) (8.0.0)\n",
            "Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.4.7)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2020.12.5)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=3.1.0->sentence-transformers) (2.10)\n",
            "Requirement already satisfied: rake-nltk in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from rake-nltk) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk->rake-nltk) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5YsN8TLNZDz4",
        "outputId": "1dc1f69c-719f-416b-a6c9-f55fbb55760b"
      },
      "source": [
        "!pip install spacy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: spacy in /usr/local/lib/python3.7/dist-packages (2.2.4)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.1.3)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.0.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (4.41.1)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.4.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (0.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.19.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy) (56.1.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy) (7.4.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy) (1.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.24.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy) (4.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rXMjLZWP2jmv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf2839f-73cf-4436-d22d-c863aff48b2d"
      },
      "source": [
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import re\n",
        "import string\n",
        "from string import punctuation\n",
        "import nltk\n",
        "import spacy\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models import Word2Vec\n",
        "nltk.download('punkt')\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial import distance\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from nltk import tokenize\n",
        "from operator import itemgetter\n",
        "import math\n",
        "from nltk.tokenize import word_tokenize \n",
        "stop_words = set(stopwords.words('english'))\n",
        "from rake_nltk import Rake\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from numpy import unique\n",
        "from spacy.lang.en import English"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ztp16yJoy_Tr"
      },
      "source": [
        "## **Reading the Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5lbBrae42jmw",
        "outputId": "02dd3d25-fa67-4c20-f9c2-885c6214c8b2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EkYMwE62jmw"
      },
      "source": [
        "data=pd.read_csv(\"/content/drive/MyDrive/drugsComTest_raw.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-nmJe-VzJ0X"
      },
      "source": [
        "## **Pre-processing the data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-3a3f2F2QUv"
      },
      "source": [
        "### **Removing symbols**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "k23U2ldV2jmx",
        "outputId": "26013e36-e853-414b-906a-47242bceeeec"
      },
      "source": [
        "df=pd.DataFrame(data=(data[\"drugName\"],data[\"review\"]))\n",
        "df=df.T\n",
        "for i in df.index:\n",
        "  df['review'][i]=df['review'][i].replace(\"&#039;\",\"'\")\n",
        "  df['review'][i]=df['review'][i].replace(\",\",\"\")\n",
        "  df['review'][i]=df['review'][i].replace(\"\\\\\",\"\")\n",
        "  df['review'][i]=df['review'][i].replace(\"\\\"\",\"\")\n",
        "  df['review'][i]=df['review'][i].replace(\"\\\"]\",\"\")\n",
        "  df['review'][i]=df['review'][i].replace(\"[\\\"\",\"\")\n",
        "  df['review'][i]=df['review'][i].replace(\"!\",\".\")\n",
        "  df['review'][i]=df['review'][i].replace(\"?\",\".\")\n",
        "df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drugName</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mirtazapine</td>\n",
              "      <td>I've tried a few antidepressants over the year...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Mesalamine</td>\n",
              "      <td>My son has Crohn's disease and has done very w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Bactrim</td>\n",
              "      <td>Quick reduction of symptoms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Contrave</td>\n",
              "      <td>Contrave combines drugs that were used for alc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Cyclafem 1 / 35</td>\n",
              "      <td>I have been on this birth control for one cycl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53761</th>\n",
              "      <td>Tamoxifen</td>\n",
              "      <td>I have taken Tamoxifen for 5 years. Side effec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53762</th>\n",
              "      <td>Escitalopram</td>\n",
              "      <td>I've been taking Lexapro (escitaploprgram) sin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53763</th>\n",
              "      <td>Levonorgestrel</td>\n",
              "      <td>I'm married 34 years old and I have no kids. T...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53764</th>\n",
              "      <td>Tapentadol</td>\n",
              "      <td>I was prescribed Nucynta for severe neck/shoul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53765</th>\n",
              "      <td>Arthrotec</td>\n",
              "      <td>It works...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>53766 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              drugName                                             review\n",
              "0          Mirtazapine  I've tried a few antidepressants over the year...\n",
              "1           Mesalamine  My son has Crohn's disease and has done very w...\n",
              "2              Bactrim                        Quick reduction of symptoms\n",
              "3             Contrave  Contrave combines drugs that were used for alc...\n",
              "4      Cyclafem 1 / 35  I have been on this birth control for one cycl...\n",
              "...                ...                                                ...\n",
              "53761        Tamoxifen  I have taken Tamoxifen for 5 years. Side effec...\n",
              "53762     Escitalopram  I've been taking Lexapro (escitaploprgram) sin...\n",
              "53763   Levonorgestrel  I'm married 34 years old and I have no kids. T...\n",
              "53764       Tapentadol  I was prescribed Nucynta for severe neck/shoul...\n",
              "53765        Arthrotec                                        It works...\n",
              "\n",
              "[53766 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RofIg8Ed1mWI"
      },
      "source": [
        "### **Grouping the data by medicine names**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "bC7t5U3I2jmy",
        "outputId": "3f8374e8-2e1a-496e-d19a-000539903ca5"
      },
      "source": [
        "df2 = df.groupby(\"drugName\")\n",
        "df_new = df2[\"review\"].apply(list)\n",
        "df_new = df_new.reset_index()\n",
        "df_new"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drugName</th>\n",
              "      <th>review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A / B Otic</td>\n",
              "      <td>[These drops helped me so much. I was in sever...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abacavir / dolutegravir / lamivudine</td>\n",
              "      <td>[I discovered my new status in July 2017 VL 94...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abacavir / lamivudine</td>\n",
              "      <td>[I've used this since first diagnosed and star...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abatacept</td>\n",
              "      <td>[In UK had this on NHS for last 7 months. Impr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abilify</td>\n",
              "      <td>[After having to pay a but load out of pocket ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2632</th>\n",
              "      <td>ZzzQuil</td>\n",
              "      <td>[Gave me rapid heart beats .........]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2633</th>\n",
              "      <td>depo-subQ provera 104</td>\n",
              "      <td>[Just recently have got Depo subQ provera for ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2634</th>\n",
              "      <td>ella</td>\n",
              "      <td>[Hello strangers. Im here to share my experien...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2635</th>\n",
              "      <td>femhrt</td>\n",
              "      <td>[Hot flashes completely gone in less than 2 we...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2636</th>\n",
              "      <td>pHisoHex</td>\n",
              "      <td>[Before Phisohex could only be purchased by pr...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2637 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  drugName                                             review\n",
              "0                               A / B Otic  [These drops helped me so much. I was in sever...\n",
              "1     Abacavir / dolutegravir / lamivudine  [I discovered my new status in July 2017 VL 94...\n",
              "2                    Abacavir / lamivudine  [I've used this since first diagnosed and star...\n",
              "3                                Abatacept  [In UK had this on NHS for last 7 months. Impr...\n",
              "4                                  Abilify  [After having to pay a but load out of pocket ...\n",
              "...                                    ...                                                ...\n",
              "2632                               ZzzQuil              [Gave me rapid heart beats .........]\n",
              "2633                 depo-subQ provera 104  [Just recently have got Depo subQ provera for ...\n",
              "2634                                  ella  [Hello strangers. Im here to share my experien...\n",
              "2635                                femhrt  [Hot flashes completely gone in less than 2 we...\n",
              "2636                              pHisoHex  [Before Phisohex could only be purchased by pr...\n",
              "\n",
              "[2637 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBhdTcZ61rv0"
      },
      "source": [
        "### **Stopword Removal and Parsing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GeQd3l702jmz"
      },
      "source": [
        "def get_text_processing(text):\n",
        "    stpword = stopwords.words('english')\n",
        "    no_punctuation = [char for char in text if char not in string.punctuation]\n",
        "    no_punctuation = ''.join(no_punctuation)\n",
        "    #nlp = English()\n",
        "    #doc = nlp(' '.join([word for word in no_punctuation.split() if word.lower() not in stpword]))\n",
        "    return ' '.join([word for word in no_punctuation.split() if word.lower() not in stpword])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L-3wlEkc1vdL"
      },
      "source": [
        "### **Creating a separate column for the refined text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "o_qojlYb2jmz",
        "outputId": "8c15202b-4ae4-457b-b202-e91ed681c157"
      },
      "source": [
        "df_new['rev'] = df_new['review'].apply(get_text_processing)\n",
        "df_new.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drugName</th>\n",
              "      <th>review</th>\n",
              "      <th>rev</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>A / B Otic</td>\n",
              "      <td>[These drops helped me so much. I was in sever...</td>\n",
              "      <td>drops helped much. severe pain 8 days finally ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abacavir / dolutegravir / lamivudine</td>\n",
              "      <td>[I discovered my new status in July 2017 VL 94...</td>\n",
              "      <td>discovered new status July 2017 VL 94K CD4 126...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abacavir / lamivudine</td>\n",
              "      <td>[I've used this since first diagnosed and star...</td>\n",
              "      <td>I've used since first diagnosed starting HAART...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abatacept</td>\n",
              "      <td>[In UK had this on NHS for last 7 months. Impr...</td>\n",
              "      <td>UK NHS last 7 months. Improved within first mo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abilify</td>\n",
              "      <td>[After having to pay a but load out of pocket ...</td>\n",
              "      <td>pay load pocket slowly found me. put hyper-man...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               drugName  ...                                                rev\n",
              "0                            A / B Otic  ...  drops helped much. severe pain 8 days finally ...\n",
              "1  Abacavir / dolutegravir / lamivudine  ...  discovered new status July 2017 VL 94K CD4 126...\n",
              "2                 Abacavir / lamivudine  ...  I've used since first diagnosed starting HAART...\n",
              "3                             Abatacept  ...  UK NHS last 7 months. Improved within first mo...\n",
              "4                               Abilify  ...  pay load pocket slowly found me. put hyper-man...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5CLni2dUWmro"
      },
      "source": [
        "## **Feature Extraction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3EodVOHF0cvo"
      },
      "source": [
        "### **Extracting keywords using BERT and RAKE**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNGyDVVJiL18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c5675f9dbdc44c859301b7d2f9cf4a33",
            "7c6e12a9490f44aea776964859a3bf97",
            "66bfbdf75b0d420684ac8a6316120dcb",
            "a98fbdced06b40adbebef133a1cd5355",
            "896babc0cc0f49afa3b68d4e9fd973fe",
            "9629b88a03c442c386f7bce7f0a8d0c3",
            "e28648d5371140349479179792d2c216",
            "709235cec4294388b411e8872a14f17d"
          ]
        },
        "outputId": "af12134d-a390-4709-f597-fab8ecd92c65"
      },
      "source": [
        "bertmodel = SentenceTransformer('distilbert-base-nli-mean-tokens')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c5675f9dbdc44c859301b7d2f9cf4a33",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=244733649.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UiAEJd0Gh3Er"
      },
      "source": [
        "def key(text):\n",
        "  r = Rake()\n",
        "  temp=text.split(' ')\n",
        "  a=[]\n",
        "  r.extract_keywords_from_sentences(temp)\n",
        "  # To get keyword phrases ranked highest to lowest.\n",
        "  r.get_ranked_phrases()\n",
        "  rakew=[]\n",
        "  # To get keyword phrases ranked highest to lowest with scores.\n",
        "  a=r.get_ranked_phrases()\n",
        "  t = 20\n",
        "  if(len(a)<20):\n",
        "    t = len(a)\n",
        "  for i in range(0,t):\n",
        "    rakew.append(a[i])\n",
        "  \n",
        "  temp=text.split(\".\")\n",
        "  all_words = [i for i in temp]\n",
        "  sent_vector=[]\n",
        "  temp=text.split(\".\")\n",
        "  t=''\n",
        "  for i in temp:\n",
        "    t+=i\n",
        "\n",
        "  n_gram_range = (1, 1)\n",
        "  stop_words = \"english\"\n",
        "\n",
        "  # Extract candidate words/phrases\n",
        "  count = CountVectorizer(ngram_range=n_gram_range, stop_words=stop_words).fit([t])\n",
        "  candidates = count.get_feature_names()\n",
        "\n",
        "  doc_embedding = bertmodel.encode([t])\n",
        "  candidate_embeddings = bertmodel.encode(candidates)\n",
        "\n",
        "  top_n = 15\n",
        "  distances = cosine_similarity(doc_embedding, candidate_embeddings)\n",
        "  keywords = [candidates[index] for index in distances.argsort()[0][-top_n:]]\n",
        "\n",
        "  f_keywords = list(keywords+rakew)\n",
        "\n",
        "  return f_keywords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJMLJ3VL0QsP"
      },
      "source": [
        "### **Calculating TF-IDF values for the keywords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEdb4u8hG8yG"
      },
      "source": [
        "def check_sent(word, sentences): \n",
        "    final = [all([w in x for w in word]) for x in sentences] \n",
        "    sent_len = [sentences[i] for i in range(0, len(final)) if final[i]]\n",
        "    return int(len(sent_len))\n",
        "\n",
        "def get_top_n(dict_elem, n):\n",
        "    result = dict(sorted(dict_elem.items(), key = itemgetter(1), reverse = True)[:n]) \n",
        "    return result.keys()\n",
        "    \n",
        "def caltfidf(total_words,text):\n",
        "  total_word_length = len(total_words)\n",
        "  total_sentences = tokenize.sent_tokenize(text)\n",
        "  total_sent_len = len(total_sentences)\n",
        "\n",
        "  tf_score = {}\n",
        "  for each_word in total_words:\n",
        "      each_word = each_word.replace('.','')\n",
        "      if each_word not in stop_words:\n",
        "          if each_word in tf_score:\n",
        "              tf_score[each_word] += 1\n",
        "          else:\n",
        "              tf_score[each_word] = 1\n",
        "\n",
        "  # Dividing by total_word_length for each dictionary element\n",
        "  tf_score.update((x, y/int(total_word_length)) for x, y in tf_score.items())\n",
        "\n",
        "  idf_score = {}\n",
        "  for each_word in total_words:\n",
        "      each_word = each_word.replace('.','')\n",
        "      if each_word not in stop_words:\n",
        "          if each_word in idf_score:\n",
        "              idf_score[each_word] = check_sent(each_word, total_sentences)\n",
        "          else:\n",
        "              idf_score[each_word] = 1\n",
        "\n",
        "  # Performing a log and divide\n",
        "  idf_score.update((x, math.log(int(total_sent_len)/y)) for x, y in idf_score.items())\n",
        "\n",
        "\n",
        "  tf_idf_score = {key: tf_score[key] * idf_score.get(key, 0) for key in tf_score.keys()}\n",
        "\n",
        "  t = 25\n",
        "  if(len(tf_idf_score)<25):\n",
        "    t = len(tf_idf_score)\n",
        "\n",
        "  tfidfw=list(get_top_n(tf_idf_score, t))\n",
        "  return tfidfw"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-4gLIVyE00m9"
      },
      "source": [
        "### **POS Tagging the resultant keywords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l56K5GzOGPOA"
      },
      "source": [
        "def features(text):\n",
        "  f_keywords = key(text)\n",
        "  tfidfw = caltfidf(f_keywords,text)\n",
        "  tfidfw = \" \".join(tfidfw)\n",
        "\n",
        "  stop_words = set(stopwords.words('english'))\n",
        "\n",
        "  tokenized = sent_tokenize(tfidfw)\n",
        "\n",
        "  for i in tokenized:\n",
        "    wordsList = nltk.word_tokenize(i)\n",
        "\n",
        "    wordsList = [w for w in wordsList if not w in stop_words]\n",
        "\n",
        "    tagged = nltk.pos_tag(wordsList)\n",
        "\n",
        "\n",
        "  \n",
        "  for i in range(0,len(tagged)):\n",
        "    if(tagged[i][1]=='JJ' or tagged[i][1]=='NN' or tagged[i][1]=='VBP' or tagged[i][1]=='VBG'):\n",
        "      print(tagged[i][0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_i_CcCh1UwV"
      },
      "source": [
        "### **Removing Stopwords from the given text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE5jq5i1w3LI"
      },
      "source": [
        "def findFeatures(text):\n",
        "    stpword = stopwords.words('english')\n",
        "    no_punctuation = [char for char in text if char not in string.punctuation]\n",
        "    no_punctuation = ''.join(no_punctuation)\n",
        "    finalText = ' '.join([word for word in no_punctuation.split() if word.lower() not in stpword])\n",
        "\n",
        "    features(finalText)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCnko2s41BfF"
      },
      "source": [
        "### **Feature Extraction for the reviews from the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diH9q9H9i8Z2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "747de221-f05a-4836-e522-41f1248c01c9"
      },
      "source": [
        "test = 7\n",
        "text = ' '.join([line for line in df_new['review'][test]])\n",
        "features(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "prostate\n",
            "hot\n",
            "night\n",
            "bone\n",
            "month\n",
            "medicine\n",
            "cancer\n",
            "zytiga\n",
            "thickness\n",
            "take\n",
            "symptom\n",
            "swollen\n",
            "side\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn-zv_zV1KCG"
      },
      "source": [
        "### **Feature Extraction for user input text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6zdORo3lw5X-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a591502-288a-4331-f369-b538b8d1970f"
      },
      "source": [
        "text = \"The surface level is the actual realization of words as they appear in the final form. The lexical level corresponds to the combination of roots and affixes that are chained together with boundary markers.\"\n",
        "findFeatures(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "combination\n",
            "actual\n",
            "appear\n",
            "affixes\n",
            "level\n",
            "form\n",
            "realization\n",
            "final\n",
            "surface\n",
            "lexical\n",
            "boundary\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYS334y80Dz5"
      },
      "source": [
        "## **Text Summarization**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At1XDGvpuuT-"
      },
      "source": [
        "def Summarizer(test):\n",
        "  df_new[\"review\"][test]\n",
        "  sentence = sent_tokenize(str(df_new[\"review\"][test]))\n",
        "  temp=df_new[\"rev\"][test].split(\".\")\n",
        "  all_words = [i for i in temp]\n",
        "  sent_vector=[]\n",
        "  for i in temp:\n",
        "      plus=0\n",
        "      for j in i.split(\".\"):\n",
        "          plus+= bertmodel.encode(j)\n",
        "      plus = plus/len(i.split(\".\"))\n",
        "      sent_vector.append(plus)\n",
        "  n_clusters = 3\n",
        "\n",
        "  kmeans = KMeans(n_clusters, init = 'k-means++', random_state = 42)\n",
        "  y_kmeans = kmeans.fit_predict(sent_vector)\n",
        "  my_list=[]\n",
        "  for i in range(n_clusters):\n",
        "      my_dict={}\n",
        "    \n",
        "      for j in range(len(y_kmeans)):\n",
        "        \n",
        "          if y_kmeans[j]==i:\n",
        "              my_dict[j] =  distance.euclidean(kmeans.cluster_centers_[i],sent_vector[j])\n",
        "      min_distance = min(my_dict.values())\n",
        "      my_list.append(min(my_dict, key=my_dict.get))\n",
        "\n",
        "  km = []                          \n",
        "  for i in sorted(my_list):\n",
        "      try:\n",
        "        km.append(sentence[i])\n",
        "      except:\n",
        "        pass\n",
        "\n",
        "\n",
        "  model = AgglomerativeClustering(n_clusters=3)\n",
        "  # fit model and predict clusters\n",
        "  yhat = model.fit_predict(sent_vector)\n",
        "  # retrieve unique clusters\n",
        "  clusters = unique(yhat)\n",
        "\n",
        "\n",
        "  my_list=[]\n",
        "  for i in range(n_clusters):\n",
        "      my_dict={}\n",
        "    \n",
        "      for j in range(len(yhat)):\n",
        "        \n",
        "          if yhat[j]==i:\n",
        "              my_dict[j] =  distance.euclidean(clusters[i],sent_vector[j])\n",
        "      min_distance = min(my_dict.values())\n",
        "      my_list.append(min(my_dict, key=my_dict.get))\n",
        "\n",
        "  ag = []                          \n",
        "  for i in sorted(my_list):\n",
        "      ag.append(sentence[i])\n",
        "\n",
        "  final_summary = list(set(km+ag))\n",
        "  print(\"Summary:\")\n",
        "  for i in final_summary:\n",
        "    print(i, end=' ')\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJPMlJ8FDuqq",
        "outputId": "81b1da71-31f6-474f-c70f-156f07be72a1"
      },
      "source": [
        "medicine_name = \"Acanya\"\n",
        "ind = df_new[df_new['drugName']==medicine_name].index.values\n",
        "test = ind[0]\n",
        "print(\"\\nMedicine Name: \", medicine_name)\n",
        "print(\"\\nReview: \", ' '.join(df_new['review'][test]), \"\\n\")\n",
        "Summarizer(test)\n",
        "print(\"\\nKeywords: \")\n",
        "findFeatures(df_new['review'][test])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Medicine Name:  Acanya\n",
            "\n",
            "Review:  Honestly this medicine has been life changing for me. Before I used it my acne was awful mostly on my forehead but all around the rest of my face too. My dermatologist prescribed it to me and within a month of using it my acne completely cleared up. Now three years later I still use it and my face remains acne free. I was breaking out badly on the sides of my cheeks then I couldn't take it anymore so I went to the dermo and they prescribed me Acanya. After 2 weeks I noticed a difference for sure. The big cysts I would get or just all these pimples I got in 1 spot started fading away instantly. It is take time I had to pop some and then put the cream on. It's been 3 months so far and no breakouts or acne whatsoever. I just use cetaphil and that medication and done. (: I LOVE this product. I suffered from breakouts (not horrible) but enough to make me self-conscious about. It does not make your face dry if anything it smooths it out. I use a tad in the morning and a whole pump at night all over my face. I haven't been getting pimples at all except for a few that were unnoticeable. And it worked almost immediately. I also paired this with Solodyn tablets 55mg for only the first month. Amazing. If anyone has mild breakouts then I strongly recommend these 2 products. Good luck. This may not work for everyone but if you have mild acne then I would go for it. I am 49 yrs old had cystic acne all my adult life. My dermatologist put me on Acanya 5 months ago and my skin looks the best it ever had.  My co-workers all think I am wearing makeup.  Have such large pores and they are shrinking too. No peeling I guess because I have oily skin.  But as an African American woman I didn't think I would ever find anything that would successfully help my skin. I am so grateful.  It just takes patience. I've always been hesitant to use acne medication in the morning because I felt like it would do nothing for me. Also I have to wear makeup before I leave the house so the only thing I usually have underneath my foundation is a moisturizer. I've added Acanya to my regime for the past week or so and my face has improved almost instantly. My pores look smaller and I haven't gotten any new bumps and the ones I already have are going away. I say stick to this product even if you don't see improvements at first. Hopefully I'll see more improvements My dermatologist gave me Acanya to use in the mornings. My acned improved a little in the beginning but then returned/got worse. It works differently for different people. I've struggled with acne since I was about 13. I've used Proactive Clean &amp; Clear Neutrogena AcneFree etc. and every other acne system you can think of. \r\n",
            "This product gets rid of my acne in about 4 days; it is all I need now. It doesn't matter what face wash or toners you use with this because all you need is the Acanya gel. It's pretty expensive but one bottle (only put on problem spots) lasts me about 4 months.\r\n",
            "\r\n",
            "Acanya has completely has kept my acne away for about a year now. As soon as you put it on the next morning the size of the bumps reduce in size dramatically. About a week later I had no acne. I didn't have bad skin I just needed the right product. I went to a new dermatologist because my acne is out of control.  I've had acne for 10 years and this is the worst it has ever been.  He gave me Acanya for the morning and it stings so bad I could cry.  My face turns red it's tight burning and not improving.  I've been using Acanya for almost a week I know results might take longer.  As for now I am not happy. Just be warned it is very drying and can make your day uncomfortable. awful product. did not do anything it was supposed to. I have very very mild acne. I wouldn't even call it acne just pimples. and everytime I have tried to use acanya it hasn't helped with any pimples and just left my face red and burned the next day. This redness stays for at least 4 days. It's so embarrassing and not worth it for a product that just makes your pimples MORE obvious because of HUGE red spots. awful product. throwing it in the garbage so I never have the idea of using it again. Also for the people saying it dries our your skin very badly you must be using too much. It does dry your skin out but not badly at all. You're supposed to use very very little bit of it on your acne. Not your whole face just your acne. I learned the hard way. I loaded it up on my chin &amp; it made my chin so dry &amp; itchy &amp; red. It looked horrible like my whole chin was scabbed. It went away after I stopped putting the cream on it for a day or two. \n",
            "\n",
            "Summary:\n",
            "Before I used it my acne was awful mostly on my forehead but all around the rest of my face too. No peeling I guess because I have oily skin. I suffered from breakouts (not horrible) but enough to make me self-conscious about. \\r\\nThis product gets rid of my acne in about 4 days; it is all I need now. Good luck. Hopefully I'll see more improvements\", 'My dermatologist gave me Acanya to use in the mornings. \n",
            "\n",
            "\n",
            "Keywords: \n",
            "acne\n",
            "dermo\n",
            "month\n",
            "everytime\n",
            "uncomfortableawful\n",
            "morning\n",
            "wash\n",
            "moisturizer\n",
            "neutrogena\n",
            "medication\n",
            "medicine\n",
            "dermatologist\n",
            "year\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-GYLjZc-_CN",
        "outputId": "a4338e53-54d0-448a-9ecd-34fd3a89d257"
      },
      "source": [
        "medicine_name = \"Acetaminophen / propoxyphene\"\n",
        "ind = df_new[df_new['drugName']==medicine_name].index.values\n",
        "test = ind[0]\n",
        "print(\"\\nMedicine Name: \", medicine_name)\n",
        "print(\"\\nReview: \", ' '.join(df_new['review'][test]), \"\\n\")\n",
        "Summarizer(test)\n",
        "print(\"\\nKeywords: \")\n",
        "findFeatures(df_new['review'][test])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Medicine Name:  Acetaminophen / propoxyphene\n",
            "\n",
            "Review:  I just got my wisdom teeth out and I'm allergic to codeine so the doctor gave me Darvocet. It doesn't make me sleepy but I am dizzy and find complex problem-solving difficult. It helps ease some of the sharp pains in my jaw but I still have a dull throbbing pain that keeps me from sleeping. If only Vicodin didn't make me vomit. I broke my back when I was 16 and have had a total of 26 surgeries in my life. Have taken Darvocet for 46 yrs now and it has saved the day. This is okay if you have a minor headache but it's very weak. I had a Hematoma when I was pregnant and they would only give this to me and it still didn't get rid of the pain and that was PAINFUL. Thought I was having a miscarriage when it first came on. I would definitely not recommend this for anything other than headaches. I have been on and off this drug in some form for over 40 years. I have had no problems of any kind.\r\n",
            "I am taking generic Butalbital Comp-Codeine #3. I can barely tell I have taken anything my pain is still so bad. I have never gotten as good a result with their products. ONLY pain medicine that I could/can take that does not have side effects.  I am sick it is no longer on the market.   really helped worked fast. I took it with food without food gave a sour stomach. Helped me to sleep too. It will for sure help with the pain.  Mine is a toothache but it makes me soo sleepy.  I sleep wonderful but find it hard to want to wake up. I have had headaches for long as I can remember (25 yrs). When nothing works you just suffer. When you find something that works you have hope and not so afraid of the pain. Darvocet is the only thing that works for me. I love it. It really helps me. I used it after carpal tunnel surgery and I felt no pain with it. I'm using it again because I have kidney stones and this is helping me again. My only problem with it is that after taking it for surgery I had withdrawal symptoms for a day or two...a nasty headache. That was the only problem with it. Davorcet is the only pain medicine I trust and it works for me. This was the only pain medication that took the pain AWAY.  No side effects.   ONLY thing that works after I've had a migraine for a while and when Tylenol Migraine or Imitrex don't work. Love it because it doesn't make me feel loopy or drowsy. Can take it and still work and most of all because it works. The best medicine there is.  You can function and feel no pain and at the same time sleep well. I have also been prescribed other medicines which are either too much or not enough. This is just right. Darvocet is a good pain reliever with just enough narcotic to make it effective. But trust me it can become addictive like anything else. I just went through withdrawal symptoms yesterday and part of today and didn't know what was going on until I looked this up on the computer and then took some to relieve the symptoms. But I believe all in all it's a safer alternative than other narcotics. This is the ONLY pain killer I can take due to Epilepsy as other pain killers cause allergic reactions or intolerance.  Having been on Darvocet or its generic formula; even in spite of the anti-epileptic medications in addition to the medical conditions including MVP (cardiac) which would put this medication on the &quot;shelf&quot; exceptionally quick. Suffered no side effects or seizures at all. Therefore must also add having had this prescribed for minor to major injuries to sprains or strains. All my medications are carefully organized whenever Darvocet is used a schedule is configured out as not to rock the boat. Must add that Physicians trusts me with this where titration I can do myself from half to quartering and off. For menstural pain and ovarian cyst. I agree with the doctor's post. This pain medicine is better for long term chronic pain and not acute pain. When I get these pains it is pretty sudden and this medicine isn't strong enough. No side effects. It helped a little with the pain not a whole lot though. I have been on Darvocet N-100 for about 30 years for rheumatoid arthritis. It has controlled most of the pain except when I'm in a full fledged flare up. I take it with methotrexate (which controls my arthritis) and now my insurance company has denied to pay for it. I did send a letter from my doctor and they still denied it.  I know this drug works for me and they suggest I change to Percocet which they pay for and it doesn't work so guess I just endure the pain. Thanks Darvocet for the pain free years. \n",
            "\n",
            "Summary:\n",
            "', \"ONLY thing that works after I've had a migraine for a while and when Tylenol Migraine or Imitrex don't work. You can function and feel no pain and at the same time sleep well. Helped me to sleep too. I know this drug works for me and they suggest I change to Percocet which they pay for and it doesn't work so guess I just endure the pain. ', \"I love it. Can take it and still work and most of all because it works. \n",
            "\n",
            "\n",
            "Keywords: \n",
            "miscarriage\n",
            "epileptic\n",
            "hematoma\n",
            "headachesi\n",
            "headache\n",
            "drowsy\n",
            "medicine\n",
            "surgery\n",
            "migraine\n",
            "arthritis\n",
            "epilepsy\n",
            "rheumatoid\n",
            "toothache\n",
            "yrs\n",
            "yrs\n",
            "yesterday\n",
            "worked\n",
            "work\n",
            "wonderful\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEdPfVA0zw6T"
      },
      "source": [
        "## **Future Improvements (LSTM)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g0COjBqZVKR"
      },
      "source": [
        "X=[]\n",
        "y=[]\n",
        "for test in range(0,len(df_new)):\n",
        "  try:\n",
        "    stri=''\n",
        "    for sen in df_new[\"review\"][test]:\n",
        "      stri=stri+sen\n",
        "    stri=stri.split(\".\")\n",
        "    stri.pop()\n",
        "    sentence = sent_tokenize(str(df_new[\"review\"][test]))\n",
        "    temp=df_new[\"rev\"][test].split(\".\")\n",
        "    temp.pop()\n",
        "    length=len(temp)\n",
        "    if (length == 1):\n",
        "      temp[0]+=\".\"\n",
        "    all_words = [i for i in temp]\n",
        "    sent_vector=[]\n",
        "    for i in temp:\n",
        "        plus=0\n",
        "        for j in i.split(\".\"):\n",
        "            plus+= embedder.encode(j)\n",
        "        plus = plus/len(i.split(\".\"))\n",
        "        sent_vector.append(plus)\n",
        "    n_clusters = (int)(length/5)+1\n",
        "    kmeans = KMeans(n_clusters, init = 'k-means++', random_state = 42)\n",
        "    y_kmeans = kmeans.fit_predict(sent_vector)\n",
        "    my_list=[]\n",
        "    for i in range(n_clusters):\n",
        "        my_dict={}\n",
        "      \n",
        "        for j in range(len(y_kmeans)):\n",
        "          \n",
        "            if y_kmeans[j]==i:\n",
        "                my_dict[j] =  distance.euclidean(kmeans.cluster_centers_[i],sent_vector[j])\n",
        "        min_distance = min(my_dict.values())\n",
        "        my_list.append(min(my_dict, key=my_dict.get))\n",
        "    temp=\"\"\n",
        "    for i in stri:\n",
        "      temp+=i\n",
        "    X.append(temp)\n",
        "    temp=\"start \"                        \n",
        "    for i in sorted(my_list):\n",
        "        if (i>=0):\n",
        "          temp+=stri[i]\n",
        "    temp+=\" end\"\n",
        "    y.append(temp)\n",
        "  except:\n",
        "    pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "svyH2ra6ZOHw"
      },
      "source": [
        "dict = {'Text': X, 'Summary': y}    \n",
        "df = pd.DataFrame(dict)\n",
        "df.to_csv('/content/drive/MyDrive/Testtrainsummary.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fG-r0i7czwbp"
      },
      "source": [
        "dat=pd.read_csv(\"/content/drive/MyDrive/Testtrainsummary.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1akvtDmz6XP"
      },
      "source": [
        "X=dat[\"Text\"]\n",
        "y=dat[\"Summary\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eNNrLe8z8AE_"
      },
      "source": [
        "import numpy as np  \n",
        "import pandas as pd \n",
        "import re           \n",
        "from bs4 import BeautifulSoup \n",
        "from keras.preprocessing.text import Tokenizer \n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from nltk.corpus import stopwords   \n",
        "from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate, TimeDistributed, Bidirectional\n",
        "from attention import AttentionLayer\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import warnings\n",
        "pd.set_option(\"display.max_colwidth\", 200)\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "96PbqntD8OYN",
        "outputId": "1d094fa0-a302-4de8-a5d0-a687639411dc"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "text_word_count = []\n",
        "summary_word_count = []\n",
        "\n",
        "# populate the lists with sentence lengths\n",
        "for i in X:\n",
        "      text_word_count.append(len(i.split()))\n",
        "\n",
        "for i in y:\n",
        "      summary_word_count.append(len(i.split()))\n",
        "\n",
        "length_df = pd.DataFrame({'text':text_word_count, 'summary':summary_word_count})\n",
        "length_df.hist(bins = 30)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzV3v-028WFt"
      },
      "source": [
        "max_len_text=600 \n",
        "max_len_summary=150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gve6cklx7ihp"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_tr,x_val,y_tr,y_val=train_test_split(X,y,test_size=0.1,random_state=0,shuffle=True) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuL318mSqPsC"
      },
      "source": [
        "#prepare a tokenizer for reviews on training data\n",
        "x_tokenizer = Tokenizer()\n",
        "x_tokenizer.fit_on_texts(list(x_tr))\n",
        "\n",
        "#convert text sequences into integer sequences\n",
        "x_tr    =   x_tokenizer.texts_to_sequences(x_tr) \n",
        "x_val   =   x_tokenizer.texts_to_sequences(x_val)\n",
        "\n",
        "#padding zero upto maximum length\n",
        "x_tr    =   pad_sequences(x_tr,  maxlen=max_len_text, padding='post') \n",
        "x_val   =   pad_sequences(x_val, maxlen=max_len_text, padding='post')\n",
        "\n",
        "x_voc_size   =  len(x_tokenizer.word_index) +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cIXHmry8ftZ"
      },
      "source": [
        "\n",
        "#preparing a tokenizer for summary on training data \n",
        "y_tokenizer = Tokenizer()\n",
        "y_tokenizer.fit_on_texts(list(y_tr))\n",
        "\n",
        "#convert summary sequences into integer sequences\n",
        "y_tr    =   y_tokenizer.texts_to_sequences(y_tr) \n",
        "y_val   =   y_tokenizer.texts_to_sequences(y_val) \n",
        "\n",
        "#padding zero upto maximum length\n",
        "y_tr    =   pad_sequences(y_tr, maxlen=max_len_summary, padding='post')\n",
        "y_val   =   pad_sequences(y_val, maxlen=max_len_summary, padding='post')\n",
        "\n",
        "y_voc_size  =   len(y_tokenizer.word_index) +1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UvFD_myC84Ff",
        "outputId": "9fe1bc1e-dff9-473e-fb8c-80e7af558a29"
      },
      "source": [
        "\n",
        "from keras import backend as K \n",
        "K.clear_session() \n",
        "latent_dim = 500 \n",
        "\n",
        "# Encoder \n",
        "encoder_inputs = Input(shape=(max_len_text,)) \n",
        "enc_emb = Embedding(x_voc_size, latent_dim,trainable=True)(encoder_inputs) \n",
        "\n",
        "#LSTM 1 \n",
        "encoder_lstm1 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.5) \n",
        "encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb) \n",
        "\n",
        "#LSTM 2 \n",
        "encoder_lstm2 = LSTM(latent_dim,return_sequences=True,return_state=True,dropout=0.5) \n",
        "encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1) \n",
        "\n",
        "#LSTM 3 \n",
        "encoder_lstm3=LSTM(latent_dim, return_state=True, return_sequences=True,dropout=0.5) \n",
        "encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2) \n",
        "\n",
        "# Set up the decoder. \n",
        "decoder_inputs = Input(shape=(None,)) \n",
        "dec_emb_layer = Embedding(y_voc_size, latent_dim,trainable=True) \n",
        "dec_emb = dec_emb_layer(decoder_inputs) \n",
        "\n",
        "#LSTM using encoder_states as initial state\n",
        "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True) \n",
        "decoder_outputs,decoder_fwd_state, decoder_back_state = decoder_lstm(dec_emb,initial_state=[state_h, state_c]) \n",
        "\n",
        "#Attention Layer\n",
        "attn_layer = AttentionLayer(name='attention_layer') \n",
        "attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs]) \n",
        "\n",
        "# Concat attention output and decoder LSTM output \n",
        "decoder_concat_input = Concatenate(axis=-1, name='concat_layer')([decoder_outputs, attn_out])\n",
        "\n",
        "#Dense layer\n",
        "decoder_dense = TimeDistributed(Dense(y_voc_size, activation='softmax')) \n",
        "decoder_outputs = decoder_dense(decoder_concat_input) \n",
        "\n",
        "# Define the model\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs) \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 600)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 600, 500)     29193500    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 600, 500), ( 2002000     embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 600, 500), ( 2002000     lstm[0][0]                       \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 500)    12806000    input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, 600, 500), ( 2002000     lstm_1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "lstm_3 (LSTM)                   [(None, None, 500),  2002000     embedding_1[0][0]                \n",
            "                                                                 lstm_2[0][1]                     \n",
            "                                                                 lstm_2[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "attention_layer (AttentionLayer ((None, None, 500),  500500      lstm_2[0][0]                     \n",
            "                                                                 lstm_3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "concat_layer (Concatenate)      (None, None, 1000)   0           lstm_3[0][0]                     \n",
            "                                                                 attention_layer[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "time_distributed (TimeDistribut (None, None, 25612)  25637612    concat_layer[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 76,145,612\n",
            "Trainable params: 76,145,612\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPVK1xYbValN"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath = \"/content/drive/MyDrive/model_training.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss',\n",
        "                             verbose=1, save_best_only=True,\n",
        "                             mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDd1Tk_A_qG0"
      },
      "source": [
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9P1j2gYu_zDq",
        "outputId": "9296704b-ed90-4263-fdf7-03220493cb0e"
      },
      "source": [
        "history=model.fit([x_tr,y_tr[:,:-1]], y_tr.reshape(y_tr.shape[0],y_tr.shape[1], 1)[:,1:] ,epochs=12,callbacks = [checkpoint],batch_size=32, validation_data=([x_val,y_val[:,:-1]], y_val.reshape(y_val.shape[0],y_val.shape[1], 1)[:,1:]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 3.4130 - accuracy: 0.5114 - val_loss: 3.5687 - val_accuracy: 0.4780\n",
            "\n",
            "Epoch 00001: loss improved from inf to 3.41301, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 2/50\n",
            "73/73 [==============================] - 208s 3s/step - loss: 3.2680 - accuracy: 0.5192 - val_loss: 3.4340 - val_accuracy: 0.4892\n",
            "\n",
            "Epoch 00002: loss improved from 3.41301 to 3.26802, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 3/50\n",
            "73/73 [==============================] - 208s 3s/step - loss: 3.1349 - accuracy: 0.5303 - val_loss: 3.3496 - val_accuracy: 0.5006\n",
            "\n",
            "Epoch 00003: loss improved from 3.26802 to 3.13490, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 4/50\n",
            "73/73 [==============================] - 208s 3s/step - loss: 3.0196 - accuracy: 0.5404 - val_loss: 3.2652 - val_accuracy: 0.5083\n",
            "\n",
            "Epoch 00004: loss improved from 3.13490 to 3.01958, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 5/50\n",
            "73/73 [==============================] - 208s 3s/step - loss: 2.8945 - accuracy: 0.5502 - val_loss: 3.1863 - val_accuracy: 0.5162\n",
            "\n",
            "Epoch 00005: loss improved from 3.01958 to 2.89448, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 6/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 2.7768 - accuracy: 0.5583 - val_loss: 3.1254 - val_accuracy: 0.5230\n",
            "\n",
            "Epoch 00006: loss improved from 2.89448 to 2.77678, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 7/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 2.6652 - accuracy: 0.5663 - val_loss: 3.0844 - val_accuracy: 0.5261\n",
            "\n",
            "Epoch 00007: loss improved from 2.77678 to 2.66521, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 8/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 2.5624 - accuracy: 0.5726 - val_loss: 3.0541 - val_accuracy: 0.5295\n",
            "\n",
            "Epoch 00008: loss improved from 2.66521 to 2.56243, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 9/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 2.4700 - accuracy: 0.5777 - val_loss: 3.0406 - val_accuracy: 0.5313\n",
            "\n",
            "Epoch 00009: loss improved from 2.56243 to 2.47002, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 10/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 2.3825 - accuracy: 0.5835 - val_loss: 3.0295 - val_accuracy: 0.5329\n",
            "\n",
            "Epoch 00010: loss improved from 2.47002 to 2.38253, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 11/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 2.3016 - accuracy: 0.5885 - val_loss: 3.0274 - val_accuracy: 0.5352\n",
            "\n",
            "Epoch 00011: loss improved from 2.38253 to 2.30162, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 12/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 2.2254 - accuracy: 0.5940 - val_loss: 3.0233 - val_accuracy: 0.5367\n",
            "\n",
            "Epoch 00012: loss improved from 2.30162 to 2.22540, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 13/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 2.1511 - accuracy: 0.6004 - val_loss: 3.0247 - val_accuracy: 0.5375\n",
            "\n",
            "Epoch 00013: loss improved from 2.22540 to 2.15113, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 14/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 2.0781 - accuracy: 0.6076 - val_loss: 3.0298 - val_accuracy: 0.5388\n",
            "\n",
            "Epoch 00014: loss improved from 2.15113 to 2.07811, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 15/50\n",
            "73/73 [==============================] - 209s 3s/step - loss: 2.0074 - accuracy: 0.6155 - val_loss: 3.0359 - val_accuracy: 0.5389\n",
            "\n",
            "Epoch 00015: loss improved from 2.07811 to 2.00738, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 16/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.9354 - accuracy: 0.6248 - val_loss: 3.0473 - val_accuracy: 0.5383\n",
            "\n",
            "Epoch 00016: loss improved from 2.00738 to 1.93538, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 17/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.8664 - accuracy: 0.6345 - val_loss: 3.0610 - val_accuracy: 0.5382\n",
            "\n",
            "Epoch 00017: loss improved from 1.93538 to 1.86636, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 18/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.7984 - accuracy: 0.6438 - val_loss: 3.0685 - val_accuracy: 0.5384\n",
            "\n",
            "Epoch 00018: loss improved from 1.86636 to 1.79841, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 19/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.7304 - accuracy: 0.6532 - val_loss: 3.0931 - val_accuracy: 0.5384\n",
            "\n",
            "Epoch 00019: loss improved from 1.79841 to 1.73044, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 20/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.6648 - accuracy: 0.6625 - val_loss: 3.1157 - val_accuracy: 0.5366\n",
            "\n",
            "Epoch 00020: loss improved from 1.73044 to 1.66483, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 21/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.6023 - accuracy: 0.6721 - val_loss: 3.1267 - val_accuracy: 0.5371\n",
            "\n",
            "Epoch 00021: loss improved from 1.66483 to 1.60231, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 22/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.5402 - accuracy: 0.6815 - val_loss: 3.1514 - val_accuracy: 0.5362\n",
            "\n",
            "Epoch 00022: loss improved from 1.60231 to 1.54017, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 23/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.4804 - accuracy: 0.6911 - val_loss: 3.1870 - val_accuracy: 0.5350\n",
            "\n",
            "Epoch 00023: loss improved from 1.54017 to 1.48044, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 24/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.4225 - accuracy: 0.7009 - val_loss: 3.2122 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00024: loss improved from 1.48044 to 1.42247, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 25/50\n",
            "73/73 [==============================] - 211s 3s/step - loss: 1.3611 - accuracy: 0.7109 - val_loss: 3.2432 - val_accuracy: 0.5331\n",
            "\n",
            "Epoch 00025: loss improved from 1.42247 to 1.36107, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 26/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.3040 - accuracy: 0.7209 - val_loss: 3.2768 - val_accuracy: 0.5333\n",
            "\n",
            "Epoch 00026: loss improved from 1.36107 to 1.30397, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 27/50\n",
            "73/73 [==============================] - 211s 3s/step - loss: 1.2508 - accuracy: 0.7307 - val_loss: 3.3063 - val_accuracy: 0.5308\n",
            "\n",
            "Epoch 00027: loss improved from 1.30397 to 1.25080, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 28/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.1957 - accuracy: 0.7406 - val_loss: 3.3349 - val_accuracy: 0.5286\n",
            "\n",
            "Epoch 00028: loss improved from 1.25080 to 1.19567, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 29/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.1371 - accuracy: 0.7515 - val_loss: 3.3806 - val_accuracy: 0.5293\n",
            "\n",
            "Epoch 00029: loss improved from 1.19567 to 1.13709, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 30/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.0867 - accuracy: 0.7617 - val_loss: 3.4170 - val_accuracy: 0.5283\n",
            "\n",
            "Epoch 00030: loss improved from 1.13709 to 1.08672, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 31/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 1.0404 - accuracy: 0.7711 - val_loss: 3.4530 - val_accuracy: 0.5288\n",
            "\n",
            "Epoch 00031: loss improved from 1.08672 to 1.04039, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 32/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.9912 - accuracy: 0.7806 - val_loss: 3.4936 - val_accuracy: 0.5266\n",
            "\n",
            "Epoch 00032: loss improved from 1.04039 to 0.99120, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 33/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.9408 - accuracy: 0.7911 - val_loss: 3.5362 - val_accuracy: 0.5253\n",
            "\n",
            "Epoch 00033: loss improved from 0.99120 to 0.94084, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 34/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.8966 - accuracy: 0.7997 - val_loss: 3.5787 - val_accuracy: 0.5233\n",
            "\n",
            "Epoch 00034: loss improved from 0.94084 to 0.89663, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 35/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.8511 - accuracy: 0.8097 - val_loss: 3.6226 - val_accuracy: 0.5217\n",
            "\n",
            "Epoch 00035: loss improved from 0.89663 to 0.85112, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 36/50\n",
            "73/73 [==============================] - 211s 3s/step - loss: 0.8064 - accuracy: 0.8199 - val_loss: 3.6971 - val_accuracy: 0.5235\n",
            "\n",
            "Epoch 00036: loss improved from 0.85112 to 0.80645, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 37/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.7645 - accuracy: 0.8292 - val_loss: 3.7400 - val_accuracy: 0.5209\n",
            "\n",
            "Epoch 00037: loss improved from 0.80645 to 0.76454, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 38/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.7243 - accuracy: 0.8386 - val_loss: 3.7686 - val_accuracy: 0.5200\n",
            "\n",
            "Epoch 00038: loss improved from 0.76454 to 0.72431, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 39/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.6875 - accuracy: 0.8468 - val_loss: 3.8337 - val_accuracy: 0.5185\n",
            "\n",
            "Epoch 00039: loss improved from 0.72431 to 0.68754, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 40/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.6615 - accuracy: 0.8520 - val_loss: 3.8577 - val_accuracy: 0.5218\n",
            "\n",
            "Epoch 00040: loss improved from 0.68754 to 0.66153, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 41/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.6281 - accuracy: 0.8605 - val_loss: 3.9064 - val_accuracy: 0.5197\n",
            "\n",
            "Epoch 00041: loss improved from 0.66153 to 0.62811, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 42/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.5960 - accuracy: 0.8676 - val_loss: 3.9405 - val_accuracy: 0.5185\n",
            "\n",
            "Epoch 00042: loss improved from 0.62811 to 0.59603, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 43/50\n",
            "73/73 [==============================] - 211s 3s/step - loss: 0.5580 - accuracy: 0.8772 - val_loss: 4.0041 - val_accuracy: 0.5182\n",
            "\n",
            "Epoch 00043: loss improved from 0.59603 to 0.55799, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 44/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.5178 - accuracy: 0.8874 - val_loss: 4.0618 - val_accuracy: 0.5166\n",
            "\n",
            "Epoch 00044: loss improved from 0.55799 to 0.51785, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 45/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.4882 - accuracy: 0.8945 - val_loss: 4.1154 - val_accuracy: 0.5164\n",
            "\n",
            "Epoch 00045: loss improved from 0.51785 to 0.48825, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 46/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.4631 - accuracy: 0.9006 - val_loss: 4.1549 - val_accuracy: 0.5174\n",
            "\n",
            "Epoch 00046: loss improved from 0.48825 to 0.46315, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 47/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.4381 - accuracy: 0.9065 - val_loss: 4.2205 - val_accuracy: 0.5170\n",
            "\n",
            "Epoch 00047: loss improved from 0.46315 to 0.43811, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 48/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.4161 - accuracy: 0.9122 - val_loss: 4.2687 - val_accuracy: 0.5143\n",
            "\n",
            "Epoch 00048: loss improved from 0.43811 to 0.41614, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 49/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.3894 - accuracy: 0.9185 - val_loss: 4.3026 - val_accuracy: 0.5153\n",
            "\n",
            "Epoch 00049: loss improved from 0.41614 to 0.38942, saving model to /content/drive/MyDrive/model_training.hdf5\n",
            "Epoch 50/50\n",
            "73/73 [==============================] - 210s 3s/step - loss: 0.3732 - accuracy: 0.9222 - val_loss: 4.3339 - val_accuracy: 0.5146\n",
            "\n",
            "Epoch 00050: loss improved from 0.38942 to 0.37317, saving model to /content/drive/MyDrive/model_training.hdf5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMfHgqL4WBXI"
      },
      "source": [
        "model.save(\"/content/drive/MyDrive/fmodel1.hdf5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_E4GWD9FJLg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "outputId": "7c976d24-a994-4bd9-cc74-d3f9576ffe0b"
      },
      "source": [
        "from matplotlib import pyplot \n",
        "pyplot.plot(history.history['loss'], label='train') \n",
        "pyplot.plot(history.history['val_loss'], label='test') \n",
        "pyplot.legend() \n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4pHZ-MIFcy7"
      },
      "source": [
        "reverse_target_word_index=y_tokenizer.index_word \n",
        "reverse_source_word_index=x_tokenizer.index_word \n",
        "target_word_index=y_tokenizer.word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8HUR9KrFfus"
      },
      "source": [
        "# encoder inference\n",
        "encoder_model = Model(inputs=encoder_inputs,outputs=[encoder_outputs, state_h, state_c])\n",
        "\n",
        "# decoder inference\n",
        "# Below tensors will hold the states of the previous time step\n",
        "decoder_state_input_h = Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = Input(shape=(latent_dim,))\n",
        "decoder_hidden_state_input = Input(shape=(max_len_text,latent_dim))\n",
        "\n",
        "# Get the embeddings of the decoder sequence\n",
        "dec_emb2= dec_emb_layer(decoder_inputs)\n",
        "\n",
        "# To predict the next word in the sequence, set the initial states to the states from the previous time step\n",
        "decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n",
        "\n",
        "#attention inference\n",
        "attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n",
        "decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n",
        "\n",
        "# A dense softmax layer to generate prob dist. over the target vocabulary\n",
        "decoder_outputs2 = decoder_dense(decoder_inf_concat)\n",
        "\n",
        "# Final decoder model\n",
        "decoder_model = Model(\n",
        "[decoder_inputs] + [decoder_hidden_state_input,decoder_state_input_h, decoder_state_input_c],\n",
        "[decoder_outputs2] + [state_h2, state_c2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ry9CcjB5FjSG"
      },
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    e_out, e_h, e_c = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1,1))\n",
        "\n",
        "    # Chose the 'start' word as the first word of the target sequence\n",
        "    target_seq[0, 0] = target_word_index['start']\n",
        "\n",
        "    stop_condition = False\n",
        "    decoded_sentence = ''\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n",
        "\n",
        "        # Sample a token'\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_token = reverse_target_word_index[sampled_token_index]\n",
        "\n",
        "        if (sampled_token!='end'):\n",
        "            decoded_sentence += ' '+sampled_token\n",
        "\n",
        "        # Exit condition: either hit max length or find stop word.\n",
        "        if (sampled_token == 'end' or len(decoded_sentence.split()) >= (max_len_summary-1)):\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1,1))\n",
        "        target_seq[0, 0] = sampled_token_index\n",
        "\n",
        "        # Update internal states\n",
        "        e_h, e_c = h, c\n",
        "\n",
        "    return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csJOOEjoFniz"
      },
      "source": [
        "def seq2summary(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if((i!=0 and i!=target_word_index['start']) and i!=target_word_index['end']):\n",
        "        newString=newString+reverse_target_word_index[i]+' '\n",
        "    return newString\n",
        "\n",
        "def seq2text(input_seq):\n",
        "    newString=''\n",
        "    for i in input_seq:\n",
        "      if(i!=0):\n",
        "        newString=newString+reverse_source_word_index[i]+' '\n",
        "    return newString"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-X2-GCEFsV7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7eb82cf4-eaa0-4836-e30a-ab3e4184c7a3"
      },
      "source": [
        "for i in range(0,10):\n",
        "  print(\"Review:\",seq2text(x_val[i]))\n",
        "  print(\"Original summary:\",seq2summary(y_val[i]))\n",
        "  print(\"Predicted summary:\",decode_sequence(x_val[i].reshape(1,max_len_text)))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review: needed to use the remaining suppositories due to itching and minor bleeding from hard stool noticed blood sugar rising about 40 pts now that i stopped using it condition somewhat better and sugars are lower \n",
            "Original summary: needed to use the remaining suppositories due to itching and minor bleeding from hard stool \n",
            "Predicted summary:  i was in a few more weeks to the pharmacy i'm not sure how this is the job of my life as soon as i stopped it as it was no longer falling off i think it is a strong drug with it\n",
            "\n",
            "\n",
            "Review: this is my second go around with this medicine my sugars stay in the 200's it makes me eat all the is an excellent addition to my regimen in controlling my i have experienced weight loss and it is very affordable my doctor gave me a value card which fixes the co pay at just 10 per month at last a new medicine that works and is affordablei am a type 2 diabetic for 13 years insulins lantus and novolog flex pen actos metformin sugar was still high a1c 119 i know it says not to be used with insulin but doctor said it would benefit me to lower my levels adding this dropped my a1c level to 65 big difference with no side effects for mei've been a diabetic for two years the first year my numbers were maxing out my meter at 9 months i started on low dose of i started feeling better then by 1 full year as diabetic i was taking a slightly higher dose i ve dropped 50lbs with the metformin and combined now at two years of taking my aic is 57 and my average blood sugar is 119 i have just been told doc wants to take me off she's concerned my numbers are to low and is even planning on getting me off metformin i am scared to of that i'm finally feeling like my old self even at 35 a month is so worth the cost \n",
            "Original summary: big difference with no side effects for mei've been a diabetic for two years at 9 months i started on low dose of i started feeling better i ve dropped 50lbs with the metformin and and my average blood sugar is 119 \n",
            "Predicted summary:  i have been taking this medication for 6 months now it caused by my right ear and when i was younger and remembered how well it worked to help me for himself\n",
            "\n",
            "\n",
            "Review: years i suffered sinus headaches which are much like migraines flonase has alleviated that tremendously i don't take this all the time just when i sense allergy season or plan to be somewhere where there is a change like the mountains or in an airplane it keeps my sinuses from swelling causing the headache it's not an instant fix it takes about 11 hours to be effective on mei have awful allergies and have since i was a kid at 30 years old i finally couldn't take it anymore and gave in and started taking medicine i take a prescription strength claritin and use flonase fluticasone propionate i really like it because it takes effect immediately i actually like the smell of it it cracks me up because it is for allergies yet smells like flowers i noticed it works best if you blow your nose first and use it first thing in the morning i did experience a mild nose bleed about a week into using it but haven't had one since and i have been using it 4 months polyps were better after 1 month of has saved my life i have always been a sneezing mess i constantly had a blocked nose more or less everyday i stupidly tried to use omg what a mistake as this infected my nose because i came reliant on it causing an inflamation so i went to the doctors who prescribed me avamys nose spray it saved my life i can breathe again and it treated my nose from inflammation and also protects it from any further complications all watery eyes and nose problems gone down the drain i would this medicine best nose spray i've ever had both generic and flonase work for me been using them for several years must use every day to see effectsi gave it a 5 out of 10 based just on my experience for two months it worked beautifully i felt so much better then i ended up with severe dizziness increased thirst and urination diarrhea weakness aches and pains also muscle spasms around the eyes and i believe higher blood pressure though i can't corroborate exactly all symptoms have gone away since quitting the one that's lingered the longest has been the increased thirst and urination apparently this medication can raise blood glucose levels in blood and urine triggering diabetes fortunately its been a little over a week since i stopped medication and those symptoms are getting better now too one day i counted i had to go to the bathroom 13 x's in a 12 hour period never again one squirt 5 mins later my vision was blurry my heart was racing my arms and legs felt like jello and 30 mins later i was having body aches all over the place like i had the flu will not be taking this medication ever againi was out on fluticasone for a severe cold with ear infection and thick head congestion that was quite persistent the doctor felt giving it a go might get the nasal passages open a bit to help with sinus pressure and fluid behind my eardrum after 10 days on it my symptoms worsened severe sore throat white patches on my throat bleeding nose and spasms that put me into coughing fits so bad i'd throw up and feel as though i would pass out from lack of air i chose to stop it 3 days ago after 2 days my throat pain improved and i felt more myself day 3 the spasms so far seem to have ended \n",
            "Original summary: symptoms are getting better now too one squirt 5 mins later my vision was blurry my heart was racing my arms and legs felt like jello and 30 mins later i was having body aches all over the place like i had the flu will not be taking this medication ever againi was out on fluticasone for a severe cold with ear infection and thick head congestion that was quite persistent the doctor felt giving it a go might get the nasal passages open a bit to help with sinus pressure and fluid behind my eardrum after 10 days on it my symptoms worsened severe sore throat white patches on my throat bleeding nose and spasms that put me into coughing fits so bad i'd throw up and feel as though i would pass out from lack of air day 3 the spasms so far seem to have ended \n",
            "Predicted summary:  my heaviest weight was 205 and as of my last time i also have taken that i had a lot better than i have been taking it for 4 weeks i was completely happy with higher blood sugar in may food no side effects\n",
            "\n",
            "\n",
            " nevertheless this medication is excellent \n",
            " nevertheless this medication is excellent \n",
            "Predicted summary:  i was told to take this medication i feel really painful though does not work at all it's a miracle for me it did not work for me\n",
            "\n",
            "\n",
            "Review: changes but i have read the reviews hoping to see some changes like u guys will keep you add no h included my 11 year old daughter is also add ritalin has always worked just fine for me however i decided to try intuniv after my dr prescribed it for my daughter saying that it was better because it wasn't habit forming and that it wasn't a stimulant after 2 weeks of feeling extremely tired i then began to have headaches feel like i was going to collapse at any given moment and couldn't even drive due to the extreme comatose state i felt i was in my vision also became blurred and i was very dizzy i can see how this medication might benefit someone with adhd as it lowers blood pressure and seems to slow the person down but i don't recommend it for add it was a miserable nightmare i took my daughter off it as welli don't care for this medicine i developed a rash on both my arms and was so confused i don't suggest adults use this for adhdmy grandson has been on this for over a month he is a different person when he is on this he is not a good eater and never has been so the doctor weighs him a lot he is only 5 but you could not stand the person he was without medication he takes this with vyvanse and it is cerebral palsy my son is 8 years old and has started taking intuniv for his behavior concentration and mood swings he does have cp he has never been diagnosed with adhd so that concerned me when the neurologist wanted to put him on intuniv he's taking 1mg at night and i have to tell you he is a new boy he's cooperative sleeping well and he is doing better in 8 year old son was prescribed 2mg in the morning he has been on it for two weeks at first it helped him concentrate in school but he was still aggressive with his sister and others week two he now cries almost everyday at school and at home he constantly talks about death he keeps asking me if i will wait for him in heaven when i die it is awful to see my little boy go through this i took him off of it right away vyvanse worked for him a lot better at the lowest guanfacine for a week have not noticed any effects except maybe my son is more argumentative but it's not helping his adhd at all strattera works much better than guanfacine since he can't take the stimulants i recommend strattera to anyone else who has had a problem with side effects from ritalin or adderallmy son was diagnosed adhd in 4th grade he's now in 7th since that time we've tried many medications we finally settled on metadate and it worked great but we kept having to up the dosage until he's now on 60mg the doctor recommended adding intuniv to the metadate he was cranky and irritable the first week but now at week 3 and 2mg dosage the crankiness seems to be getting better what i have seen with intuniv is that he's very difficult to get up in the mornings but on a good note if i miss the metadate medication his behavior is still pretty good he's not bouncing all over the house when he's on both the medications he's doing really good i do have hopes to eventually get him off the stimulant all together \n",
            "Original summary: back to her full 2mg dose ever since he he has been out of control bouncing off the walls non stop his psychiatrist this happens to many of his patients who have taken it for a long time he sleeps well and feels good during the daymy son is 11 yrs old and was diagnosed with adhd since he was 6 yrs and was on other medicines for 2 yrs nowi don't care for this medicine i developed a rash on both my arms and was so confused i don't suggest adults use this for grandson has been on this for over a cerebral palsy my son is 8 years old and has started taking intuniv for his behavior concentration and mood swings he has been on it for two weeks strattera works much better than since he can't take the stimulants he's not bouncing all over the house \n",
            "Predicted summary:  i've tried consistent breast cancer for about 5 years and it has reduced my life from the results at the first few days i was able to get my skin off of it because of my face has made me extremely sick i will let you know that this medication is supposed to do not even but it is supposed to work for me sorry aczone is great but it seems to be the worst so i usually read on this bc while on my face is less painful than any acne with less consistent with a new face face head at 1 but one pill was great skin no noticeable side effects none of the breast area acne worse i got so dark went off it will be completely better than normal face face face along with the breast bleeding seems to be worse it seems to be\n",
            "\n",
            "\n",
            "Review: i have had some of the same side effectsbut the one is well worth the otheri no longer experience the dread of having a heart a young age i have been on blood pressure meds since i was now 45 yo been on several different meds for my blood stuff works just fine it's getting it that's the problem it seems to be back ordered from the manufacturers and it's a struggle to get it now i'm out and can't seem to get anyone to get more for me even though they keep promising now i'm left scrambling to get to my doctor to change medications in midstream stay had been on a bunch of others that did next to nothing and the side effects were awful within a couple weeks of started edarbyclor 40 125 i was down to 125 85 from 165 95 i also found a pharmacy where they are able to sell it to me for 10 month with their discount card \n",
            "Original summary: i have had some of the same side the one is well worth the other been on several different meds for my blood pressure it seems to be back ordered from the manufacturers and it's a struggle to get it within a couple weeks of started edarbyclor 40 12 \n",
            "Predicted summary:  i have been taking 100mg for 4 years now with no side effects for pain in the past year i was at a pharmacy no one thing when they are the worst culpritbeen taking this medication for almost 2 years after taking prevacid from the problem i don't know they are the best since they were so intense rheumatoid arthritis with arthritis and they may not go back to normal my doctor put me on 100mg 15 mg per day for scaring in my esophagusi have tried many diabetes for the past 17 years now at the cancer did nothing i had the worst of my bladder and it has also makes my doctor who has had from bladder off of medications for over a year and i had a problem with it\n",
            "\n",
            "\n",
            "Review: exceptionally good product to relieve mild dermatitis symptoms it has come in 2 part a large bottle of liquid and a capsule of the active ingredient if you are not going to use the product immediately tell the pharmacist to not mix the products for you the solution is good only for 3 months from the date of on holiday in hot sunny climates i always suffer from severe heat rash after using synalar cream it clears after a day or so it is brilliant \n",
            "Original summary: when on holiday in hot sunny climates i always suffer from severe heat rash after using cream it clears after a day or so it is brilliant \n",
            "Predicted summary:  i have yellow problems with less side effects than the way of them it was the most effective medication i've tried the top of the skin it has less dry and less than when i was able to get rid of the pills of the 250 mg advair i give it a 10 out of it for about ten days i had an allergic reaction to the medicine i had the nausea some way it subsided the first two days about 3 days later and my skin has improved and my cancer was approved by the way as the medicine lasts a good pills at least but as the results it has gotten so much better than some of the nausea or not the relief i had some noticeable side effects that i had some relief from the first two weeks in the past\n",
            "\n",
            "\n",
            "Review: for several years now and found it to work very well for me now i find that none of the in my area of texas are carrying it any more anyone know why to the question of whether or not did my insurance cover this drug it is an otc no insurance requiredi have had the oxytrol patch on for only about 24 hours and understand that it takes between 24 and 48 hours to notice any improvement so i have noticed no improvement yet it does not stick well and i have had to put adhesive tape around the edges of the patch to keep it on i don't know if i picked a bad spot middle of my stomach but certain ways it turn it seems to pinch i used nicotine patches years ago and it seems that if these patches were smaller and less rigid they might adhere a little better i like the idea of a patch lasting 3 4 days but i would prefer using one smaller patch a day if they stuck to the skin betteri absolutely love this patch thank you for putting it back on the shelves i am only 45 and had trouble since my hysterectomy several years ago in fact i was wearing a diaper to too sexy i admit these patches are awesome and have given me back my life they do get less sticky in the shower but i just face my body the other way the come off with no problem with goo gone or baby oil well worth iti recently started using the patch i have had to wear a pad everyday prior to using it i'm only on day 6 second patch and i feel like my life has changed i can walk exercise even sneeze and have no problem i was concerned about the adhesive because i have allergies and sensitive skin but i haven't had an issue i place the patch on my lower abdomen off to the side i removed the excess adhesive with baby oil and q tips it came right off i'll definitely keep using this seems to be the best medication for me i have only tried one other for the overactive bladder however this was the best medication due to the side effects which were basically at first now i've had stomach pain for the last 3 days i'm on my 3rd patch not sure if i should stop or helped with frequent urination i was able to sleep all night finally gave me severe dry mouth and sinus issues had to stop takingi want to thank merck and it's scientist that developed this patch and i am so glad it is over the counter now i have worn the patch for one month now i am on my second box and will be purchasing a third a forth and so on oxytrol has changed my life back to normal no standing up and urine flowing out uncontrollably anymore no more 12 15 trips to the bathroom a day i travel and now i can drive for 2 3 hours at a time without stopping for a bathroom now i change the patch on day 4 i did try to hold out for the 4th night and while i did not have the urgency problem i did have to urinate more frequently than if i go four days and three nights the adhesive problems and the crinkling i don't care better then a didn't work for me i was disappointed since i like the idea of a patch \n",
            "Original summary: a miracle to the question of whether or not did my insurance cover this drug it is an otc no insurance required i like the idea of a patch lasting 3 4 days but i would prefer using one smaller patch a day if they stuck to the skin better in fact i was wearing a diaper to too sexy i admit these patches are awesome and have given me back my life they do get less sticky in the shower but i just face my body the other way the come off with no problem with gone or baby oil i was concerned about the adhesive because i have allergies and sensitive skin but i haven't had an issue it came right seems to be the best medication for me had to stop didn't work for me i was disappointed since i like the idea of a patch \n",
            "Predicted summary:  i have tried several different medications as the only one that was with oxygen i have never had any problems with it\n",
            "\n",
            "\n",
            " the new pill helped too but i will never underestimate the power of the pink stuff 6 thank you god \n",
            "Original summary: first trip to er me prednisone benadryl and zantac which helped with the swelling but not the crazy itching thank you god \n",
            "Predicted summary:  i've suffered with severe diarrhea with joint pain and diarrhea for the first time in one i had watery diarrhea\n",
            "\n",
            "\n",
            " i seriously would not use this on any type of fungal irritation it also did nothing other than more irritation for a this product is more harmful than helpfuli still use this medicine as a standby as it reduces the itching associated with jock itch i may have picked up a resistant strain as the doctor has prescribed a new cream with betamethasone dipropionate and clotrimazole mixed in as a base i hope this worksi've had skin peeling on my feet all my life never has any ointment healed the condition as does it is fantastic \n",
            "Original summary: this product is more harmful than helpful i hope this worksi've had skin peeling on my feet all my life it is fantastic \n",
            "Predicted summary:  the medicine sucks or the pain was getting better my life is getting better i'm less than the psoriasis and decided to start something i would give it a try something else on this is the same medicine as i had the same time after my own and i was able to do much better again\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ME4bpA4kTZ-W"
      },
      "source": [
        "Review: exceptionally good product to relieve mild dermatitis symptoms it has come in 2 part a large bottle of liquid and a capsule of the active ingredient if you are not going to use the product immediately tell the pharmacist to not mix the products for you the solution is good only for 3 months from the date of on holiday in hot sunny climates i always suffer from severe heat rash after using synalar cream it clears after a day or so it is brilliant \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Original summary: when on holiday in hot sunny climates i always suffer from severe heat rash after using cream it clears after a day or so it is brilliant \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Predicted summary:  i have yellow problems with less side effects than the way of them it was the most effective medication i've tried the top of the skin it has less dry and less than when i was able to get rid of the pills of the 250 mg advair i give it a 10 out of it for about ten days i had an allergic reaction to the medicine i had the nausea some way it subsided the first two days about 3 days later and my skin has improved and my cancer was approved by the way as the medicine lasts a good pills at least but as the results it has gotten so much better than some of the nausea or not the relief i had some noticeable side effects that i had some relief from the first two weeks in the past"
      ]
    }
  ]
}