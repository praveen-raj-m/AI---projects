# Optimization of hyper parameters of Neural Network

Neural Nets are one of the fastest growing aspects of AI with a wide and versatile
range of applications. For these models to be used in various applications it is
required to be accurate. To achieve this, it must have suitable hyper parameters and
weights to train with. These hyper parameters are the main problem and need to be
found out. There are no perfect set of hyper parameters for a particular application.
The technique of finding the right hyper parameters works by means of trial and
error. In this project Meta heuristic algorithms such as Genetic
Algorithm and Particle Swarm Optimization algorithm are used to find the optimum set of
hyper parameters for training a Neural Net model that can give best results.
Comparision between the optimization algorithms are done with various factors like
computation time, time to convergence inorder to find the best one.

DATASET USED :

Fashion-MNIST is a dataset of Zalando's article imagesâ€”consisting of a training
set of 60,000 examples and a test set of 10,000 examples. Each example is a 28x28
grayscale image, associated with a label from 10 classes. It shares the same image
size and structure of training and testing splits. It is intended that Fashion-MNIST
will serve as a direct drop-in replacement for the original MNIST dataset for
benchmarking machine learning algorithms. Being a vast dataset with minimalist
properties makes this dataset an excellent choice for exploration and comparison of
these algorithms.
